{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch environment test and versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.3 | packaged by Anaconda, Inc. | (main, May 15 2023, 15:41:31) [MSC v.1916 64 bit (AMD64)]\n",
      "Xarray version: 2023.5.0\n",
      "PyTorch version: 2.0.1+cu118\n",
      "PyTorch Vision version: 0.15.2+cu118\n",
      "PyTorch Lightning Version: 2.0.3\n",
      "CUDA version: 11.8\n",
      "CUDNN version: 8.7.0\n",
      "Found 1 CUDA Devices:\n",
      "00: NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "     8 GB\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "# PyTorch, TorchVision, Lightning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "# datacube related\n",
    "import xarray as xr\n",
    "\n",
    "# additional libraries\n",
    "import pynvml\n",
    "pynvml.nvmlInit()\n",
    "import seaborn as sns\n",
    "\n",
    "# Version outputs\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Xarray version: {xr.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PyTorch Vision version: {torchvision.__version__}\")\n",
    "print(f\"PyTorch Lightning Version: {pl.__version__}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "cudnn_version = torch.backends.cudnn.version()\n",
    "print(f\"CUDNN version: {cudnn_version//1000}.{(cudnn_version%1000)//100}.{(cudnn_version%100)//10}\")\n",
    "#available_devices = [torch.cuda.device(i) for i in range(torch.cuda.device_count())]\n",
    "available_devices = [range(torch.cuda.device_count())]\n",
    "print(f\"Found {len(available_devices)} CUDA Devices:\")\n",
    "for idx, gpu_id in enumerate(available_devices):\n",
    "    gpu_mem = round(pynvml.nvmlDeviceGetMemoryInfo(pynvml.nvmlDeviceGetHandleByIndex(idx)).total/1024**3)\n",
    "    print(f\"{idx:02}: {torch.cuda.get_device_name(gpu_id)}\")\n",
    "    print(f\"    {gpu_mem:2} GB\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML4Earth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
